{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Poisson regression with Tensorflow\n",
    "*Gorkem Ozkaya*\n",
    "\n",
    "In this notebook we will perform a Poisson regression with Google's Deep Learning library Tensorflow. Although Tensorflow is not designed for traditional modeling tasks such as Poisson regression, we still can benefit from the flexibility of Tensorflow. Starting from shallow models like these, one can later obtain deeper versions of Poisson regression and other GLM's, which can handle nonlinearaties and variable interactions. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import statsmodels.api as sm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generating data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def gen_data(N = 10000):\n",
    "    data = np.random.uniform(-1, 1, (N, 3))\n",
    "    data = sm.add_constant(data)\n",
    "    data = pd.DataFrame(data, columns = ['intercept', 'Var1', 'Var2', 'Var3'])\n",
    "    lam = np.exp(-2*data['intercept'] + data['Var1'] - 0.5*data['Var2'] + 0.3*data['Var3'] )\n",
    "    resp = np.random.poisson(lam = lam)\n",
    "    data['lam'] = lam\n",
    "    data['resp'] = resp\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dtrain = gen_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stating Poisson regression as an optimization problem\n",
    "Let $X$ be the design matrix, $w$ be the model coefficient vector and $y$ be the observed response. Let $\\hat y = \\exp(Xw)$ be the estimated mean by the model. We are looking for the coefficient vector $w$ that maximizes the likelihood\n",
    "$$\n",
    "\\sum_{i = 1}^N \\frac{\\hat y_i^{y_i} e^{-\\hat y_i}}{y_i!},\n",
    "$$\n",
    "where $y = (y_i)_i$ and $\\hat y = (\\hat y)_i$.  Taking logarithms and removing the constants, this problem is equivalent to minimizing the loss function\n",
    "$$\n",
    "   L =  -\\sum_{i=1}^N \\left(y_i \\log(\\hat y_i) - \\hat y_i \\right).\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fitting the model with Tensorflow\n",
    "Having defined the objective function, now we can set the Tensorflow model. With its automatic differentiation support, Tensorflow automatically calculates the gradients of mathematical expressions, hence can do gradient descent optimization on them. We chose *Adam* as the optimization algorithm. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X = tf.constant(dtrain[['intercept', 'Var1', 'Var2', 'Var3']].as_matrix(), name = 'X', dtype=tf.float32)\n",
    "y = tf.constant(value = list(dtrain['resp']), dtype = tf.float32, name='y', shape=(dtrain.shape[0], 1))\n",
    "\n",
    "w = tf.Variable(tf.zeros([4, 1]))\n",
    "\n",
    "y_hat = tf.exp(tf.matmul(X, w))\n",
    "\n",
    "loss_function = tf.reduce_mean(-y*tf.log(y_hat)+y_hat)\n",
    "\n",
    "train_step = tf.train.AdamOptimizer(0.001).minimize(loss_function)\n",
    "init = tf.initialize_all_variables()\n",
    "session = tf.InteractiveSession()\n",
    "session.run(init)\n",
    "\n",
    "for i in xrange(10000):\n",
    "    session.run(train_step)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The result "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-2.0227828 ],\n",
       "       [ 1.03491652],\n",
       "       [-0.53388983],\n",
       "       [ 0.32387733]], dtype=float32)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comparison with the statsmodels package \n",
    "To check the results, we repeat solving the same regression problem using the statsmodel library:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "poisson_family = sm.families.family.Poisson(link=sm.genmod.families.links.log)\n",
    "poisson_model = sm.GLM(dtrain['resp'], dtrain[['intercept', 'Var1', 'Var2', 'Var3']], family=poisson_family)\n",
    "poisson_results = poisson_model.fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>Generalized Linear Model Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>        <td>resp</td>       <th>  No. Observations:  </th>  <td> 10000</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                 <td>GLM</td>       <th>  Df Residuals:      </th>  <td>  9996</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model Family:</th>        <td>Poisson</td>     <th>  Df Model:          </th>  <td>     3</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Link Function:</th>         <td>log</td>       <th>  Scale:             </th>    <td>1.0</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>               <td>IRLS</td>       <th>  Log-Likelihood:    </th> <td> -4407.1</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>           <td>Thu, 22 Dec 2016</td> <th>  Deviance:          </th> <td>  5713.9</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>               <td>18:41:02</td>     <th>  Pearson chi2:      </th> <td>9.78e+03</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Iterations:</th>         <td>9</td>        <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "      <td></td>         <th>coef</th>     <th>std err</th>      <th>z</th>      <th>P>|z|</th> <th>[95.0% Conf. Int.]</th> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>intercept</th> <td>   -2.0228</td> <td>    0.030</td> <td>  -67.464</td> <td> 0.000</td> <td>   -2.082    -1.964</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Var1</th>      <td>    1.0349</td> <td>    0.047</td> <td>   22.157</td> <td> 0.000</td> <td>    0.943     1.126</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Var2</th>      <td>   -0.5339</td> <td>    0.044</td> <td>  -12.245</td> <td> 0.000</td> <td>   -0.619    -0.448</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Var3</th>      <td>    0.3239</td> <td>    0.043</td> <td>    7.558</td> <td> 0.000</td> <td>    0.240     0.408</td>\n",
       "</tr>\n",
       "</table>"
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                 Generalized Linear Model Regression Results                  \n",
       "==============================================================================\n",
       "Dep. Variable:                   resp   No. Observations:                10000\n",
       "Model:                            GLM   Df Residuals:                     9996\n",
       "Model Family:                 Poisson   Df Model:                            3\n",
       "Link Function:                    log   Scale:                             1.0\n",
       "Method:                          IRLS   Log-Likelihood:                -4407.1\n",
       "Date:                Thu, 22 Dec 2016   Deviance:                       5713.9\n",
       "Time:                        18:41:02   Pearson chi2:                 9.78e+03\n",
       "No. Iterations:                     9                                         \n",
       "==============================================================================\n",
       "                 coef    std err          z      P>|z|      [95.0% Conf. Int.]\n",
       "------------------------------------------------------------------------------\n",
       "intercept     -2.0228      0.030    -67.464      0.000        -2.082    -1.964\n",
       "Var1           1.0349      0.047     22.157      0.000         0.943     1.126\n",
       "Var2          -0.5339      0.044    -12.245      0.000        -0.619    -0.448\n",
       "Var3           0.3239      0.043      7.558      0.000         0.240     0.408\n",
       "==============================================================================\n",
       "\"\"\""
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "poisson_results.summary()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
